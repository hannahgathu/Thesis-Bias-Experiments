{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prepared-pregnancy",
   "metadata": {},
   "source": [
    "In this notebook we will experiment with the AL bias mitigation technique from Richards. \n",
    "We will do this on a synthetically biased sample (sample size=700) that we obtained from the CERN dataset, with the rf classifier trained on 10 percent of the data and using a=1/28 and k=0 for the bin distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some notes:\n",
    "# - If you use df.loc[i], you get the instance that had index i in the original dataframe.\n",
    "# - If you use df.l=iloc[i], you get the ith instance n the current dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comfortable-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-diversity",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "difficult-milwaukee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(url):\n",
    "\n",
    "    url = url + \"?raw=true\"\n",
    "    df = pd.read_csv(url, encoding='cp1252', sep=',', low_memory=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "signed-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = read_file(\"https://github.com/hannahgathu/Thesis-Data-Visualisations/blob/main/Data/benchmark_data/Test_datasets/bias_and_noise/CERN_testing_set_300_1000.csv\")\n",
    "df = read_file(\"https://github.com/hannahgathu/Thesis-Data-Visualisations/blob/main/Data/benchmark_data/Test_datasets/bias_and_noise/CERN_testing_set_50_300.csv\")\n",
    "df_og = read_file(\"https://github.com/hannahgathu/Thesis-Data-Visualisations/blob/main/Data/benchmark_data/dielectron_classification.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-attempt",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "internal-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample and pool, the sample has size 700\n",
    "df['s1']=df['pz1']\n",
    "df['s2']=df['pz2']\n",
    "\n",
    "sample=df[df['in_biased_sample']==1]\n",
    "pool=df[df['in_biased_sample']==0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-binary",
   "metadata": {},
   "source": [
    "### Add extra bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decent-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add noise to s\n",
    "for i in range(sample.shape[0]):\n",
    "    sample['s1'].at[i]=sample['s1'][i]+np.random.normal(0,30)\n",
    "    \n",
    "#add noise to s\n",
    "for i in range(sample.shape[0]):\n",
    "    sample['s2'].at[i]=sample['s2'][i]+np.random.normal(0,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "streaming-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=sample[(sample['s1'] < 30) & (sample['s1']>-30) & (sample['s2'] < 30) & (sample['s2']>-30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "inappropriate-walker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "endangered-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_og=sample\n",
    "pool_og=pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dried-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=sample_og\n",
    "pool=pool_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "different-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['M>21.3','M','Run','Event','in_biased_sample','s1', 's2'])\n",
    "y=df.M>21.3\n",
    "X_pool=pool.drop(columns=['M>21.3','M','Run','Event','in_biased_sample','s1', 's2'])\n",
    "X_sample = sample.drop(columns=['M>21.3','M','Run','Event','in_biased_sample','s1', 's2'])\n",
    "y_pool=pool.M>21.3\n",
    "y_sample=sample.M>21.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alternative-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_og=df_og.drop(columns=['M>21.3','M','Run','Event'])\n",
    "y_og=df_og.M>21.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-terry",
   "metadata": {},
   "source": [
    "# Train rf classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "satisfactory-wesley",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0.088 s\n"
     ]
    }
   ],
   "source": [
    "#train classifier on sample\n",
    "rf = RandomForestClassifier()\n",
    "t0 = time()\n",
    "rf.fit(X_sample.drop(X_sample.columns[0], axis=1).drop(X_sample.columns[1], axis=1), y_sample)\n",
    "print ('training time: ', round(time()-t0, 3), 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cubic-anderson",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting time:  0.012 s\n",
      "Accuracy: 0.5914285714285714\n"
     ]
    }
   ],
   "source": [
    "#accuracy on X (whole set)\n",
    "t1=time()\n",
    "pred_rf = rf.predict(X.drop(X_sample.columns[0], axis=1).drop(X_sample.columns[1], axis=1))\n",
    "print ('predicting time: ', round(time()-t1, 3), 's')\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sonic-sculpture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57437\n"
     ]
    }
   ],
   "source": [
    "pred_rf = rf.predict(X_og)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_og, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-graduate",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "virtual-technical",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##get proximity matrix\n",
    "def get_proximity_matrix(X, rf):\n",
    "    \n",
    "    #find proportion of indices that match between i and j\n",
    "    #compute the symmetric matrix\n",
    "    \n",
    "    n=X.shape[0]\n",
    "    tree_idxs = rf.apply(X.drop(X_sample.columns[0], axis=1).drop(X_sample.columns[1], axis=1))\n",
    "    proximity_matrix = np.empty(shape=(n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        #for j in range(i,n):\n",
    "        for j in range(n):\n",
    "            proximity_matrix[i,j] = np.sum(np.equal(tree_idxs[i,:], tree_idxs[j,:]))\n",
    "    return proximity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "outer-maria",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##get maximum probabilities\n",
    "def get_max_class_probabilities(X,rf):\n",
    "    class_probabilities= rf.predict_proba(X.drop(X_sample.columns[0], axis=1).drop(X_sample.columns[1], axis=1))\n",
    "    max_class_probabilities=[0]*(len(class_probabilities))\n",
    "    for i in range (len(class_probabilities)):\n",
    "        max_class_probabilities[i]=max(class_probabilities[i,0],class_probabilities[i,1])\n",
    "    return max_class_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "junior-evening",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X=training set, pool=pool of instances to pick from\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_sample,y_sample)\n",
    "#proximity_matrix=get_proximity_matrix(X+pool,rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-providence",
   "metadata": {},
   "source": [
    "## AL query functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alleged-energy",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sum_of_proximities(i1, ys, proximity_matrix):\n",
    "    proximities=[0]*len(ys)\n",
    "    for i in range(len(ys)):\n",
    "        proximities[i]=max(proximity_matrix[i,i1],proximity_matrix[i1,i])\n",
    "    sum_of_proximities=sum(proximities)\n",
    "    return sum_of_proximities\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "horizontal-arrival",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def s_2(i, proximity_matrix):\n",
    "    S_2 = get_sum_of_proximities(i, X_pool.index, proximity_matrix)*(1-max_class_probabilities[i])/(get_sum_of_proximities(i, X_sample.index, proximity_matrix)+1)\n",
    "    return S_2\n",
    "\n",
    "def uncertainty(i):\n",
    "    return (1- max_class_probabilities[i])\n",
    "    \n",
    "def query_instance (X_sample, X_pool, rf, proximity_matrix, query_mode=\"s2\"):\n",
    "    max_class_probabilities= get_max_class_probabilities(X, rf)\n",
    "    #proximity_matrix = get_proximity_matrix(X, rf)\n",
    "    \n",
    "    if (query_mode==\"s2\"):\n",
    "        s_2_scores=[0]*X_pool.shape[0] \n",
    "    else: uncertainty_scores=[0]*X_pool.shape[0]\n",
    "    \n",
    "    for i in range(X_pool.shape[0]):\n",
    "        if (query_mode==\"s2\"):\n",
    "            s_2_scores[i]=s_2(int(X_pool.iloc[i].iloc[0]), proximity_matrix)\n",
    "        else: uncertainty_scores[i]= uncertainty(int(X_pool.iloc[i].iloc[0]))\n",
    "    if (query_mode==\"s2\"):\n",
    "        queried_instance_index = int(X_pool.iloc[np.argmax(s_2_scores)].iloc[0])\n",
    "    else: queried_instance_index = int(X_pool.iloc[np.argmax(uncertainty_scores)].iloc[0])\n",
    "    return queried_instance_index\n",
    "\n",
    "    #what I want to do:\n",
    "    #get all values of s2 for the instances in the pool in a list\n",
    "    #get the argmax, which gives the index i with the highest s2 score\n",
    "    #get the instancce from the pool by using \n",
    "    #int(X_sample.iloc[0].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-steel",
   "metadata": {},
   "source": [
    "## Compare with and without density criterium for different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "harmful-intro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting mitigation\n",
      "0 time:  1.338 s\n",
      "10 time:  9.176 s\n",
      "20 time:  16.902 s\n",
      "30 time:  25.112 s\n",
      "40 time:  32.991 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-d23342bb8fd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#store metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mpred_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_og\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_og\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_rf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#classification_report = metrics.classification_report(y_og, pred_rf, output_dict=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beatg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    628\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m--> 630\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beatg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    681\u001b[0m                      for j in np.atleast_1d(self.n_classes_)]\n\u001b[0;32m    682\u001b[0m         \u001b[0mlock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m         Parallel(n_jobs=n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    684\u001b[0m                  \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequire\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sharedmem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m             delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,\n",
      "\u001b[1;32mc:\\users\\beatg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beatg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beatg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beatg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beatg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beatg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beatg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beatg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\beatg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     \"\"\"\n\u001b[1;32m--> 467\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beatg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    934\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_of_iterations=100\n",
    "\n",
    "\n",
    "sample_size  = sample.shape[0]\n",
    "pool_size = pool.shape[0]\n",
    "\n",
    "#run AL algorithm without density criterium\n",
    "queried_instances=[]\n",
    "rf = RandomForestClassifier()\n",
    "sensitivities=[0]*n_of_iterations\n",
    "f1scores=[0]*n_of_iterations\n",
    "precisions=[0]*n_of_iterations\n",
    "accuracies=[0]*n_of_iterations\n",
    "auc_scores=[0]*n_of_iterations\n",
    "\n",
    "print(\"starting mitigation\")\n",
    "t0 = time()\n",
    "for i in range(n_of_iterations):\n",
    "    # one iteration of the AL algorithm:\n",
    "    #retrain classifier\n",
    "    rf.fit(X_sample.drop(X_sample.columns[0], axis=1).drop(X_sample.columns[1], axis=1), y_sample)\n",
    "\n",
    "    #store metrics\n",
    "    pred_rf = rf.predict(X_og)\n",
    "    accuracies[i] = metrics.accuracy_score(y_og, pred_rf)\n",
    "    #classification_report = metrics.classification_report(y_og, pred_rf, output_dict=True)\n",
    "    sensitivities[i]= metrics.recall_score(y_og, pred_rf)\n",
    "    f1scores[i]= metrics.f1_score(y_og, pred_rf)\n",
    "    precisions[i]= metrics.precision_score(y_og, pred_rf)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_og, pred_rf)\n",
    "    auc_scores[i]= metrics.auc(fpr, tpr)\n",
    "\n",
    "    #query instance and add to sample\n",
    "    max_class_probabilities= get_max_class_probabilities(X, rf)\n",
    "        #query instance and add to sample\n",
    "    if (i%10 == 0):\n",
    "        proximity_matrix = get_proximity_matrix(X, rf)\n",
    "        print (i,'time: ', round(time()-t0, 3), 's')\n",
    "        \n",
    "        #save model\n",
    "        #joblib.dump(rf, './models/{}.joblib'.format(i))\n",
    "    \n",
    "    n = query_instance(X_sample, X_pool, rf, proximity_matrix, \"uncertainty\")\n",
    "    X_pool=X_pool.drop(n)\n",
    "    y_pool=y_pool.drop(n)\n",
    "    X_sample = X_sample.append(X.loc[n])\n",
    "    y_sample = pd.concat([y_sample, pd.DataFrame([y.loc[n]])], axis = 0)\n",
    "    queried_instances.append(n)\n",
    "    \n",
    "    #overwrite queried instances\n",
    "    queried_instances_df=pd.DataFrame(queried_instances)\n",
    "    queried_instances_df.to_csv('queried_instances')\n",
    "\n",
    "#store final metrics\n",
    "pred_rf = rf.predict(X_og)\n",
    "accuracies[n_of_iterations-1] = metrics.accuracy_score(y_og, pred_rf)\n",
    "sensitivities[n_of_iterations-1] = metrics.recall_score(y_og, pred_rf)\n",
    "f1scores[n_of_iterations-1] = metrics.f1_score(y_og, pred_rf)\n",
    "precisions[n_of_iterations-1] = metrics.precision_score(y_og, pred_rf)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_og, pred_rf)\n",
    "auc_scores[n_of_iterations-1]= metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "#store stuff\n",
    "accuracies_without_density = accuracies\n",
    "queried_instances_without_density=queried_instances\n",
    "confusion_matrix_without_density=metrics.confusion_matrix(y_og, pred_rf)\n",
    "sensitivities_without_density=sensitivities\n",
    "f1scores_without_density=f1scores\n",
    "auc_scores_without_density=auc_scores\n",
    "precisions_without_density=precisions\n",
    "final_sample_without_density=sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
