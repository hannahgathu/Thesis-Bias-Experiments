{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "advance-vietnam",
   "metadata": {},
   "source": [
    "In this notebook we will experiment with the AL bias mitigation technique from Richards. \n",
    "We will do this on a synthetically biased sample (sample size=700) that we obtained from the CERN dataset, with the rf classifier trained on 10 percent of the data and using a=1/28 and k=0 for the bin distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "educational-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some notes:\n",
    "# - If you use df.loc[i], you get the instance that had index i in the original dataframe.\n",
    "# - If you use df.l=iloc[i], you get the ith instance n the current dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "alternative-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from time import time\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-stationery",
   "metadata": {},
   "source": [
    "## Read parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "enhanced-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_df = sys.argv[1]\n",
    "#path_to_df_og = sys.argv[1]\n",
    "#n_of_iterations = sys.argv[3]\n",
    "n_of_iterations=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-distributor",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "oriental-shopper",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(url):\n",
    "\n",
    "    url = url + \"?raw=true\"\n",
    "    df = pd.read_csv(url, encoding='cp1252', sep=',', low_memory=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "sufficient-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = read_file(\"https://github.com/hannahgathu/Thesis-Data-Visualisations/blob/main/Data/benchmark_data/Test_datasets/bias_and_noise/CERN_testing_set_300_1000.csv\")\n",
    "df = read_file(\"https://github.com/hannahgathu/Thesis-Data-Visualisations/blob/main/Data/benchmark_data/Test_datasets/bias_and_noise/CERN_testing_set_50_300.csv\")\n",
    "df_og = read_file(\"https://github.com/hannahgathu/Thesis-Data-Visualisations/blob/main/Data/benchmark_data/dielectron_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "protective-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og = df_og.rename(columns={\"M>21.3\":\"y\"})\n",
    "df = df.rename(columns={\"M>21.3\":\"y\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-english",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "painted-formation",
   "metadata": {},
   "source": [
    "## Create sample and pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "productive-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=df[df['in_biased_sample']==1]\n",
    "pool=df[df['in_biased_sample']==0]\n",
    "\n",
    "X=df.drop(columns=['y','M','Run','Event','in_biased_sample'])\n",
    "y=df.y\n",
    "X_pool=pool.drop(columns=['y','M','Run','Event','in_biased_sample'])\n",
    "X_sample = sample.drop(columns=['y','M','Run','Event','in_biased_sample'])\n",
    "y_pool=pool.y\n",
    "y_sample=sample.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "mechanical-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_og=df_og.drop(columns=['y','M','Run','Event'])\n",
    "y_og=df_og.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "sonic-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save starting sample and pool\n",
    "sample.to_csv('starting_sample')\n",
    "pool.to_csv('starting_pool')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-terry",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "artistic-captain",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##get maximum probabilities\n",
    "def get_max_class_probabilities(X,rf):\n",
    "    class_probabilities= rf.predict_proba(X.drop(X_sample.columns[0], axis=1).drop(X_sample.columns[1], axis=1))\n",
    "    max_class_probabilities=[0]*(len(class_probabilities))\n",
    "    for i in range (len(class_probabilities)):\n",
    "        max_class_probabilities[i]=max(class_probabilities[i,0],class_probabilities[i,1])\n",
    "    return max_class_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fewer-mirror",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X=training set, pool=pool of instances to pick from\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_sample,y_sample)\n",
    "#proximity_matrix=get_proximity_matrix(X+pool,rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-illness",
   "metadata": {},
   "source": [
    "## AL query functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "molecular-finnish",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def uncertainty(i):\n",
    "    return (1- max_class_probabilities[i])\n",
    "    \n",
    "def query_instance (X_sample, X_pool, rf):\n",
    "    max_class_probabilities= get_max_class_probabilities(X, rf)\n",
    "    #proximity_matrix = get_proximity_matrix(X, rf)\n",
    "    \n",
    "    uncertainty_scores=[0]*X_pool.shape[0]\n",
    "    \n",
    "    for i in range(X_pool.shape[0]):\n",
    "        uncertainty_scores[i]= uncertainty(int(X_pool.iloc[i].iloc[0]))\n",
    "    queried_instance_index = int(X_pool.iloc[np.argmax(uncertainty_scores)].iloc[0])\n",
    "    return queried_instance_index\n",
    "\n",
    "    #what I want to do:\n",
    "    #get all values of s2 for the instances in the pool in a list\n",
    "    #get the argmax, which gives the index i with the highest s2 score\n",
    "    #get the instancce from the pool by using \n",
    "    #int(X_sample.iloc[0].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-apartment",
   "metadata": {},
   "source": [
    "## Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "conventional-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('models') \n",
    "os.mkdir('query_scores') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-paris",
   "metadata": {},
   "source": [
    "## Create metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "willing-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = ['accuracy', 'balanced_accuracy','recall', 'precision', 'auc', 'pr_auc', 'f1_score', 'f2_score', 'log_loss']\n",
    "metrics_table = pd.DataFrame(0, index=np.arange(n_of_iterations+1), columns=metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "weighted-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_metrics (i, y_pred, y_og):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_og, y_pred)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_og, y_pred)\n",
    "    metrics_list=[metrics.accuracy_score(y_og, y_pred),\n",
    "                  metrics.balanced_accuracy_score(y_og, y_pred),\n",
    "                  metrics.recall_score(y_og, y_pred),\n",
    "                  metrics.precision_score(y_og, y_pred),\n",
    "                  metrics.auc(fpr, tpr),\n",
    "                  metrics.auc(recall, precision),\n",
    "                  metrics.f1_score(y_og, y_pred),\n",
    "                  metrics.fbeta_score(y_og, y_pred, 2),\n",
    "                  metrics.log_loss(y_og, y_pred)\n",
    "                 ]\n",
    "    metrics_table.loc[i]= metrics_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-packet",
   "metadata": {},
   "source": [
    "## Mitigate bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "spatial-aquarium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  0.79 s\n",
      "time:  8.969 s\n",
      "time:  17.355 s\n",
      "time:  25.753 s\n",
      "time:  34.434 s\n"
     ]
    }
   ],
   "source": [
    "sample_size  = sample.shape[0]\n",
    "pool_size = pool.shape[0]\n",
    "\n",
    "#run AL algorithm without density criterium\n",
    "queried_instances=[]\n",
    "rf = RandomForestClassifier()\n",
    "t0 = time()\n",
    "\n",
    "for i in range(n_of_iterations):\n",
    "    # one iteration of the AL algorithm:\n",
    "    #retrain classifier\n",
    "    rf.fit(X_sample.drop(X_sample.columns[0], axis=1).drop(X_sample.columns[1], axis=1), y_sample)\n",
    "\n",
    "    #store metrics\n",
    "    y_pred = rf.predict(X_og)\n",
    "    store_metrics(i, y_pred, y_og)\n",
    "    \n",
    "    #save metrics\n",
    "    metrics_table.to_csv('metrics_table')\n",
    "\n",
    "\n",
    "    #recalculate class probabilities and proximity matrix\n",
    "    max_class_probabilities= get_max_class_probabilities(X, rf)\n",
    "    \n",
    "    if (i%10 == 0):\n",
    "        print ('time: ', round(time()-t0, 3), 's')\n",
    "        #save model\n",
    "        joblib.dump(rf, './models/{}.joblib'.format(i))\n",
    "        \n",
    "    \n",
    "    #query instance and add to sample\n",
    "    n = query_instance(X_sample, X_pool, rf)\n",
    "    X_pool=X_pool.drop(n)\n",
    "    y_pool=y_pool.drop(n)\n",
    "    X_sample = X_sample.append(X.loc[n])\n",
    "    y_sample = pd.concat([y_sample, pd.DataFrame([y.loc[n]])], axis = 0)\n",
    "    queried_instances.append(n)\n",
    "    \n",
    "    #overwrite queried instances\n",
    "    queried_instances_df=pd.DataFrame(queried_instances)\n",
    "    queried_instances_df.to_csv('queried_instances')\n",
    "\n",
    "#store final metrics\n",
    "y_pred = rf.predict(X_og)\n",
    "store_metrics(n_of_iterations, y_pred, y_og)\n",
    "#save metrics\n",
    "metrics_table.to_csv('metrics_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-columbus",
   "metadata": {},
   "source": [
    "## Save files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
