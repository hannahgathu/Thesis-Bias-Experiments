{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coupled-pound",
   "metadata": {},
   "source": [
    "In this notebook we will experiment with the AL bias mitigation technique from Richards. \n",
    "We will do this on a synthetically biased sample (sample size=700) that we obtained from the CERN dataset, with the rf classifier trained on 10 percent of the data and using a=1/28 and k=0 for the bin distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "convertible-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some notes:\n",
    "# - If you use df.loc[i], you get the instance that had index i in the original dataframe.\n",
    "# - If you use df.l=iloc[i], you get the ith instance n the current dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "adjustable-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from time import time\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-exposure",
   "metadata": {},
   "source": [
    "## Read parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "powered-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_df = sys.argv[1]\n",
    "#path_to_df_og = sys.argv[1]\n",
    "#n_of_iterations = sys.argv[3]\n",
    "n_of_iterations=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-operator",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "quantitative-forge",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(url):\n",
    "\n",
    "    url = url + \"?raw=true\"\n",
    "    df = pd.read_csv(url, encoding='cp1252', sep=',', low_memory=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "retained-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = read_file(\"https://github.com/hannahgathu/Thesis-Data-Visualisations/blob/main/Data/benchmark_data/Test_datasets/bias_and_noise/CERN_testing_set_300_1000.csv\")\n",
    "df = read_file(\"https://github.com/hannahgathu/Thesis-Data-Visualisations/blob/main/Data/benchmark_data/Test_datasets/bias_and_noise/CERN_testing_set_30_2000.csv\")\n",
    "df_og = read_file(\"https://github.com/hannahgathu/Thesis-Data-Visualisations/blob/main/Data/benchmark_data/dielectron_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "functioning-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og = df_og.rename(columns={\"M>21.3\":\"y\"})\n",
    "df = df.rename(columns={\"M>21.3\":\"y\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-entrepreneur",
   "metadata": {},
   "source": [
    "## Create sample and pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "respected-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=df[df['in_biased_sample']==1]\n",
    "pool=df[df['in_biased_sample']==0]\n",
    "\n",
    "X=df.drop(columns=['y','M','Run','Event','in_biased_sample'])\n",
    "y=df.y\n",
    "X_pool=pool.drop(columns=['y','M','Run','Event','in_biased_sample'])\n",
    "X_sample = sample.drop(columns=['y','M','Run','Event','in_biased_sample'])\n",
    "y_pool=pool.y\n",
    "y_sample=sample.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "becoming-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_og=df_og.drop(columns=['y','M','Run','Event'])\n",
    "y_og=df_og.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "waiting-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save starting sample and pool\n",
    "sample.to_csv('starting_sample')\n",
    "pool.to_csv('starting_pool')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-hormone",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "reduced-fortune",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##get proximity matrix\n",
    "def get_proximity_matrix(X, rf):\n",
    "    \n",
    "    #find proportion of indices that match between i and j\n",
    "    #compute the symmetric matrix\n",
    "    \n",
    "    n=X.shape[0]\n",
    "    tree_idxs = rf.apply(X.drop(X_sample.columns[0], axis=1).drop(X_sample.columns[1], axis=1))\n",
    "    proximity_matrix = np.empty(shape=(n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i,n):\n",
    "            proximity_matrix[i,j] = np.sum(np.equal(tree_idxs[i,:], tree_idxs[j,:]))\n",
    "    return proximity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "occupational-national",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##get maximum probabilities\n",
    "def get_max_class_probabilities(X,rf):\n",
    "    class_probabilities= rf.predict_proba(X.drop(X_sample.columns[0], axis=1).drop(X_sample.columns[1], axis=1))\n",
    "    max_class_probabilities=[0]*(len(class_probabilities))\n",
    "    for i in range (len(class_probabilities)):\n",
    "        max_class_probabilities[i]=max(class_probabilities[i,0],class_probabilities[i,1])\n",
    "    return max_class_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "convertible-acting",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X=training set, pool=pool of instances to pick from\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_sample,y_sample)\n",
    "#proximity_matrix=get_proximity_matrix(X+pool,rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-robinson",
   "metadata": {},
   "source": [
    "## AL query functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "informational-commerce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sum_of_proximities(i1, ys, proximity_matrix):\n",
    "    proximities=[0]*len(ys)\n",
    "    for i in range(len(ys)):\n",
    "        proximities[i]=max(proximity_matrix[i,i1],proximity_matrix[i1,i])\n",
    "    sum_of_proximities=sum(proximities)\n",
    "    return sum_of_proximities\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "weekly-earthquake",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def s_2(i, proximity_matrix):\n",
    "    S_2 = get_sum_of_proximities(i, X_pool.index, proximity_matrix)*(1-max_class_probabilities[i])/(get_sum_of_proximities(i, X_sample.index, proximity_matrix)+1)\n",
    "    return S_2\n",
    "\n",
    "def uncertainty(i):\n",
    "    return (1- max_class_probabilities[i])\n",
    "    \n",
    "def query_instance (X_sample, X_pool, rf, proximity_matrix, query_mode=\"s2\"):\n",
    "    max_class_probabilities= get_max_class_probabilities(X, rf)\n",
    "    #proximity_matrix = get_proximity_matrix(X, rf)\n",
    "    \n",
    "    if (query_mode==\"s2\"):\n",
    "        s_2_scores=[0]*X_pool.shape[0] \n",
    "    else: uncertainty_scores=[0]*X_pool.shape[0]\n",
    "    \n",
    "    for i in range(X_pool.shape[0]):\n",
    "        if (query_mode==\"s2\"):\n",
    "            s_2_scores[i]=s_2(int(X_pool.iloc[i].iloc[0]), proximity_matrix)\n",
    "        else: uncertainty_scores[i]= uncertainty(int(X_pool.iloc[i].iloc[0]))\n",
    "    if (query_mode==\"s2\"):\n",
    "        queried_instance_index = int(X_pool.iloc[np.argmax(s_2_scores)].iloc[0])\n",
    "    else: queried_instance_index = int(X_pool.iloc[np.argmax(uncertainty_scores)].iloc[0])\n",
    "    return queried_instance_index\n",
    "\n",
    "    #what I want to do:\n",
    "    #get all values of s2 for the instances in the pool in a list\n",
    "    #get the argmax, which gives the index i with the highest s2 score\n",
    "    #get the instancce from the pool by using \n",
    "    #int(X_sample.iloc[0].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-order",
   "metadata": {},
   "source": [
    "## Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "stupid-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('models') \n",
    "os.mkdir('query_scores') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-reminder",
   "metadata": {},
   "source": [
    "## Create metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "amber-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = ['accuracy', 'balanced_accuracy','recall', 'precision', 'auc', 'pr_auc', 'f1_score', 'f2_score', 'log_loss']\n",
    "metrics_table = pd.DataFrame(0, index=np.arange(n_of_iterations+1), columns=metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "offensive-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_metrics (i, y_pred, y_og):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_og, y_pred)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_og, y_pred)\n",
    "    metrics_list=[metrics.accuracy_score(y_og, y_pred),\n",
    "                  metrics.balanced_accuracy_score(y_og, y_pred),\n",
    "                  metrics.recall_score(y_og, y_pred),\n",
    "                  metrics.precision_score(y_og, y_pred),\n",
    "                  metrics.auc(fpr, tpr),\n",
    "                  metrics.auc(recall, precision),\n",
    "                  metrics.f1_score(y_og, y_pred),\n",
    "                  metrics.fbeta_score(y_og, y_pred, 2),\n",
    "                  metrics.log_loss(y_og, y_pred)\n",
    "                 ]\n",
    "    metrics_table.loc[i]= metrics_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-boating",
   "metadata": {},
   "source": [
    "## Mitigate bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "previous-vessel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  12.155 s\n",
      "time:  33.11 s\n",
      "time:  58.875 s\n",
      "time:  85.774 s\n",
      "time:  113.602 s\n",
      "time:  141.588 s\n",
      "time:  170.028 s\n",
      "time:  197.894 s\n",
      "time:  224.755 s\n",
      "time:  251.873 s\n"
     ]
    }
   ],
   "source": [
    "sample_size  = sample.shape[0]\n",
    "pool_size = pool.shape[0]\n",
    "\n",
    "#run AL algorithm without density criterium\n",
    "queried_instances=[]\n",
    "rf = RandomForestClassifier()\n",
    "t0 = time()\n",
    "\n",
    "for i in range(n_of_iterations):\n",
    "    # one iteration of the AL algorithm:\n",
    "    #retrain classifier\n",
    "    rf.fit(X_sample.drop(X_sample.columns[0], axis=1).drop(X_sample.columns[1], axis=1), y_sample)\n",
    "\n",
    "    #store metrics\n",
    "    y_pred = rf.predict(X_og)\n",
    "    store_metrics(i, y_pred, y_og)\n",
    "    \n",
    "    #save metrics\n",
    "    metrics_table.to_csv('metrics_table')\n",
    "\n",
    "\n",
    "    #recalculate class probabilities and proximity matrix\n",
    "    max_class_probabilities= get_max_class_probabilities(X, rf)\n",
    "    \n",
    "    if (i%10 == 0):\n",
    "        proximity_matrix = get_proximity_matrix(X, rf)\n",
    "        print ('time: ', round(time()-t0, 3), 's')\n",
    "        \n",
    "        #save model\n",
    "        joblib.dump(rf, './models/{}.joblib'.format(i))\n",
    "        \n",
    "    \n",
    "    #query instance and add to sample\n",
    "    n = query_instance(X_sample, X_pool, rf, proximity_matrix, \"uncertainty\")\n",
    "    X_pool=X_pool.drop(n)\n",
    "    y_pool=y_pool.drop(n)\n",
    "    X_sample = X_sample.append(X.loc[n])\n",
    "    y_sample = pd.concat([y_sample, pd.DataFrame([y.loc[n]])], axis = 0)\n",
    "    queried_instances.append(n)\n",
    "    \n",
    "    #overwrite queried instances\n",
    "    queried_instances_df=pd.DataFrame(queried_instances)\n",
    "    queried_instances_df.to_csv('queried_instances')\n",
    "\n",
    "#store final metrics\n",
    "y_pred = rf.predict(X_og)\n",
    "store_metrics(n_of_iterations, y_pred, y_og)\n",
    "#save metrics\n",
    "metrics_table.to_csv('metrics_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-provincial",
   "metadata": {},
   "source": [
    "## Save files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
